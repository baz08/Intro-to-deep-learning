# -*- coding: utf-8 -*-
"""Week 3 histopathologic cancer detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DrylL_4IxpLk5sZqQHMCKDfDuB7Rx5-o

For this assignment I will be performing  histopathologic cancer utilizing a baseline CNN model and a custom tuned cnn model with some hyper parameter tuning.
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

histopathologic_cancer_detection_path = kagglehub.competition_download('histopathologic-cancer-detection')

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras import layers, models, applications
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
import cv2
import warnings
warnings.filterwarnings('ignore')
# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

"""After importing and loading the kaggle competition dataset we need to do some exploratory Data analysis. First we take a look at the dataset information we have."""

base_path = kagglehub.competition_download('histopathologic-cancer-detection')
train_labels = pd.read_csv(f'{base_path}/train_labels.csv')
train_dir = os.path.join(base_path, 'train')
test_dir = os.path.join(base_path, 'test')
print(f"Downloaded data to: {base_path}")

print(f"\nDataset loaded successfully!")
print(f"Total training images: {len(train_labels):,}")
print(f"Positive cases: {train_labels['label'].sum():,} ({train_labels['label'].mean():.2%})")
print(f"Negative cases: {(len(train_labels) - train_labels['label'].sum()):,}")

print(f"Total training images: {len(train_labels)}")
print(f"Positive cases: {train_labels['label'].sum()}")
print(f"Negative cases: {len(train_labels) - train_labels['label'].sum()}")

# Check class balance
fig, axes = plt.subplots(2, 4, figsize=(15, 8))
axes = axes.flatten()

# Plot class distribution
ax = axes[0]
sns.countplot(x='label', data=train_labels, ax=ax)
ax.set_title('Class Distribution')
ax.set_xlabel('Label (0=Negative, 1=Positive)')
ax.set_ylabel('Count')

# Sample images
sample_pos = train_labels[train_labels['label'] == 1].sample(3, random_state=42)
sample_neg = train_labels[train_labels['label'] == 0].sample(3, random_state=42)

for i, (_, row) in enumerate(sample_pos.iterrows(), 1):
    img_path = os.path.join(train_dir, f"{row['id']}.tif")
    img = cv2.imread(img_path)
    ax = axes[i]
    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    ax.set_title(f'Positive Sample {i}')
    ax.axis('off')

for i, (_, row) in enumerate(sample_neg.iterrows(), 4):
    img_path = os.path.join(train_dir, f"{row['id']}.tif")
    img = cv2.imread(img_path)
    ax = axes[i]
    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    ax.set_title(f'Negative Sample {i-3}')
    ax.axis('off')

axes[7].axis('off')
plt.tight_layout()
plt.show()

"""We successfully accessed the dataset and we can see that we have around 220,000 images with 89,117 being positive cases (around 40 percent). We then begin the process of turning these images into recognizable data for the cnn we will train. We also then proceed to split the dataset into batches for faster training."""

class DataGenerator(tf.keras.utils.Sequence):
    """Custom data generator with augmentation"""

    def __init__(self, df, img_dir, batch_size=32, img_size=(96, 96),
                 shuffle=True, augment=False, subset_fraction=1.0):
        self.df = df.sample(frac=subset_fraction, random_state=42).reset_index(drop=True)
        self.img_dir = img_dir
        self.batch_size = batch_size
        self.img_size = img_size
        self.shuffle = shuffle
        self.augment = augment
        self.indexes = np.arange(len(self.df))
        self.on_epoch_end()

    def __len__(self):
        return int(np.ceil(len(self.df) / self.batch_size))

    def __getitem__(self, index):
        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
        X = np.zeros((len(batch_indexes), *self.img_size, 3), dtype=np.float32)
        y = np.zeros((len(batch_indexes), 1), dtype=np.float32)

        for i, idx in enumerate(batch_indexes):
            img_id = self.df.loc[idx, 'id']
            label = self.df.loc[idx, 'label']

            img_path = os.path.join(self.img_dir, f"{img_id}.tif")
            img = cv2.imread(img_path)
            img = cv2.resize(img, self.img_size)
            img = img / 255.0

            if self.augment:
                img = self.augment_image(img)

            X[i] = img
            y[i] = label

        return X, y

    def augment_image(self, img):
        """Apply random augmentations"""
        # Random flips
        if np.random.random() > 0.5:
            img = np.fliplr(img)
        if np.random.random() > 0.5:
            img = np.flipud(img)

        # Random rotation
        if np.random.random() > 0.5:
            angle = np.random.uniform(-20, 20)
            h, w = img.shape[:2]
            center = (w // 2, h // 2)
            M = cv2.getRotationMatrix2D(center, angle, 1.0)
            img = cv2.warpAffine(img, M, (w, h),
                                borderMode=cv2.BORDER_REFLECT_101)

        # Random brightness/contrast
        if np.random.random() > 0.5:
            img = img * np.random.uniform(0.8, 1.2)
            img = np.clip(img, 0, 1)

        return img

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indexes)
# ============================================
# CREATE TRAIN/VAL SPLIT
# ============================================
# Use stratified split to maintain class balance
train_df, val_df = train_test_split(
    train_labels,
    test_size=0.2,
    stratify=train_labels['label'],
    random_state=42
)
print(f"\nTrain set size: {len(train_df):,}")
print(f"Validation set size: {len(val_df):,}")

# Create data generators (using subset for faster experimentation)
train_gen = DataGenerator(train_df, train_dir, batch_size=64,
                         augment=True, shuffle=True, subset_fraction=0.1)
val_gen = DataGenerator(val_df, train_dir, batch_size=64,
                       augment=False, shuffle=False, subset_fraction=0.1)

print(f"\nData generators created:")
print(f"Training batches: {len(train_gen)}")
print(f"Validation batches: {len(val_gen)}")

"""We then proceed to create our baseline CNN block with 3 convolutional layer blocks each with batch normalization, pooling, and an increasing drop out. the final layer, our classification layer then utilizes a sigmoid function to convert our classifications to labels. We then proceed to create and summarize the model."""

# ============================================
# MODEL 1: BASELINE CNN
# ============================================
print("\n" + "="*50)
print("MODEL 1: Baseline CNN Architecture")
print("="*50)

def create_baseline_cnn(input_shape=(96, 96, 3)):
    """
    Simple CNN for baseline comparison
    Architecture: Conv → Pool → Conv → Pool → Dense
    Reasoning: Good starting point, fast to train, easy to interpret
    """
    model = models.Sequential([
        # First conv block
        layers.Conv2D(32, (3, 3), activation='relu', padding='same',
                     input_shape=input_shape),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.2),

        # Second conv block
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),

        # Third conv block
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.4),

        # Classification head
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(1, activation='sigmoid')
    ])

    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]
    )

    return model

# Create and summarize
model1 = create_baseline_cnn()
print("Model 1 Summary:")
model1.summary()

# ============================================
# TRAIN MODEL 1
# ============================================
print("\nTraining Model 1...")

callbacks = [
    EarlyStopping(monitor='val_auc', patience=5, mode='max',
                  restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3,
                     min_lr=1e-6, verbose=1),
    ModelCheckpoint('model1_best.h5', monitor='val_auc',
                   mode='max', save_best_only=True, verbose=1)
]

history1 = model1.fit(
    train_gen,
    validation_data=val_gen,
    epochs=15,
    callbacks=callbacks,
    verbose=1
)

# ============================================
# EVALUATE MODEL 1
# ============================================
print("\nEvaluating Model 1...")

# Get predictions
val_gen_no_shuffle = DataGenerator(val_df, train_dir, batch_size=64,
                                  augment=False, shuffle=False, subset_fraction=1.0)
y_true = []
y_pred = []

for i in range(len(val_gen_no_shuffle)):
    X_batch, y_batch = val_gen_no_shuffle[i]
    preds = model1.predict(X_batch, verbose=0)
    y_true.extend(y_batch.flatten())
    y_pred.extend(preds.flatten())

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Calculate metrics
auc1 = roc_auc_score(y_true, y_pred)
y_pred_binary = (y_pred > 0.5).astype(int)
cm = confusion_matrix(y_true, y_pred_binary)

print(f"Model 1 - Validation AUC: {auc1:.4f}")
print(f"Confusion Matrix:\n{cm}")
print(f"Classification Report:\n{classification_report(y_true, y_pred_binary)}")

# Save Model 1 results
model1_results = {
    'name': 'Baseline CNN',
    'auc': auc1,
    'history': history1,
    'model': model1,
    'predictions': y_pred
}

"""Here we finish training the model with 15 epochs of the training batch. we can see from our classification report that we have a precision of .90 for False and .82 for positive with a recall score of .88 and .85 respectively. We then create a tranfer learning with finetuning model."""

# ============================================
# MODEL 2: EFFICIENTNET TRANSFER LEARNING
# ============================================
print("\n" + "="*50)
print("MODEL 2: EfficientNet Transfer Learning")
print("="*50)

def create_efficientnet_model(input_shape=(96, 96, 3)):
    """
    Transfer learning with EfficientNetB0
    Architecture: EfficientNet backbone + custom head
    Reasoning:
    - Pretrained on ImageNet (1.4M images)
    - Excellent feature extraction capability
    - Efficient architecture (good accuracy/computation tradeoff)
    - Particularly good for medical images due to learned hierarchical features
    """
    # Load pretrained EfficientNetB0
    base_model = applications.EfficientNetB0(
        include_top=False,
        weights='imagenet',
        input_shape=input_shape,
        pooling='avg'
    )

    # Freeze base model initially (optional: fine-tune later)
    base_model.trainable = False

    # Create model
    inputs = layers.Input(shape=input_shape)
    x = base_model(inputs, training=False)

    # Custom classification head
    x = layers.Dropout(0.5)(x)
    x = layers.Dense(256, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.3)(x)
    x = layers.Dense(128, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    outputs = layers.Dense(1, activation='sigmoid')(x)

    model = models.Model(inputs=inputs, outputs=outputs)

    # Two-phase compilation
    model.compile(
        optimizer=Adam(learning_rate=0.0001),
        loss='binary_crossentropy',
        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]
    )

    return model, base_model

# Create model
model2, base_model2 = create_efficientnet_model()
print("Model 2 Summary:")
model2.summary()

# ============================================
# TRAIN MODEL 2 - PHASE 1 (Feature extraction)
# ============================================
print("\nTraining Model 2 - Phase 1 (Feature Extraction)...")

callbacks2 = [
    EarlyStopping(monitor='val_auc', patience=5, mode='max',
                  restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3,
                     min_lr=1e-7, verbose=1),
    ModelCheckpoint('model2_phase1_best.h5', monitor='val_auc',
                   mode='max', save_best_only=True, verbose=1)
]

history2_phase1 = model2.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10,
    callbacks=callbacks2,
    verbose=1
)

# ============================================
# TRAIN MODEL 2 - PHASE 2 (Fine-tuning)
# ============================================
print("\nTraining Model 2 - Phase 2 (Fine-tuning)...")

# Unfreeze some layers for fine-tuning
base_model2.trainable = True

# Fine-tune from this layer onwards
fine_tune_at = 150
for layer in base_model2.layers[:fine_tune_at]:
    layer.trainable = False

# Recompile with lower learning rate
model2.compile(
    optimizer=Adam(learning_rate=1e-5),
    loss='binary_crossentropy',
    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]
)

callbacks2_ft = [
    EarlyStopping(monitor='val_auc', patience=5, mode='max',
                  restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3,
                     min_lr=1e-7, verbose=1),
    ModelCheckpoint('model2_final_best.h5', monitor='val_auc',
                   mode='max', save_best_only=True, verbose=1)
]

history2_phase2 = model2.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10,
    callbacks=callbacks2_ft,
    verbose=1
)

# ============================================
# EVALUATE MODEL 2
# ============================================
print("\nEvaluating Model 2...")

# Get predictions
y_pred2 = []
for i in range(len(val_gen_no_shuffle)):
    X_batch, _ = val_gen_no_shuffle[i]
    preds = model2.predict(X_batch, verbose=0)
    y_pred2.extend(preds.flatten())

y_pred2 = np.array(y_pred2)
auc2 = roc_auc_score(y_true, y_pred2)
y_pred2_binary = (y_pred2 > 0.5).astype(int)
cm2 = confusion_matrix(y_true, y_pred2_binary)

print(f"Model 2 - Validation AUC: {auc2:.4f}")
print(f"Confusion Matrix:\n{cm2}")

# Save Model 2 results
model2_results = {
    'name': 'EfficientNet Transfer',
    'auc': auc2,
    'history': (history2_phase1, history2_phase2),
    'model': model2,
    'predictions': y_pred2
}

# ============================================
# MODEL 3: CUSTOM DEEP CNN WITH ATTENTION
# ============================================
print("\n" + "="*50)
print("MODEL 3: Custom Deep CNN with Attention")
print("="*50)

def create_attention_cnn(input_shape=(96, 96, 3)):
    """
    Custom CNN with attention mechanism
    Architecture: Multiple conv blocks with residual connections + attention
    Reasoning:
    - Attention helps model focus on important tissue regions
    - Residual connections help with gradient flow in deep networks
    - Custom design allows optimization for specific problem
    """
    def channel_attention_module(input_tensor, ratio=8):
        """Channel attention block (what to focus on)"""
        channels = input_tensor.shape[-1]

        # Global pooling
        avg_pool = layers.GlobalAveragePooling2D()(input_tensor)
        max_pool = layers.GlobalMaxPooling2D()(input_tensor)

        # Shared MLP
        avg_pool = layers.Reshape((1, 1, channels))(avg_pool)
        max_pool = layers.Reshape((1, 1, channels))(max_pool)

        shared_layers = models.Sequential([
            layers.Dense(channels // ratio, activation='relu', use_bias=False),
            layers.Dense(channels, activation='sigmoid', use_bias=False)
        ])

        avg_out = shared_layers(avg_pool)
        max_out = shared_layers(max_pool)

        # Combine
        channel_attention = layers.Add()([avg_out, max_out])
        channel_attention = layers.Activation('sigmoid')(channel_attention)

        return layers.Multiply()([input_tensor, channel_attention])

    inputs = layers.Input(shape=input_shape)

    # Initial stem
    x = layers.Conv2D(32, (3, 3), padding='same')(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)
    x = layers.MaxPooling2D((2, 2))(x)

    # Block 1 with attention
    residual = x
    x = layers.Conv2D(64, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)
    x = layers.Conv2D(64, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)

    # Apply channel attention
    x = channel_attention_module(x)

    # Skip connection
    if residual.shape[-1] != 64:
        residual = layers.Conv2D(64, (1, 1), padding='same')(residual)
    x = layers.Add()([x, residual])
    x = layers.Activation('relu')(x)
    x = layers.MaxPooling2D((2, 2))(x)
    x = layers.Dropout(0.3)(x)

    # Block 2 with attention
    residual = x
    x = layers.Conv2D(128, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)
    x = layers.Conv2D(128, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)

    # Apply channel attention
    x = channel_attention_module(x)

    # Skip connection
    if residual.shape[-1] != 128:
        residual = layers.Conv2D(128, (1, 1), padding='same')(residual)
    x = layers.Add()([x, residual])
    x = layers.Activation('relu')(x)
    x = layers.MaxPooling2D((2, 2))(x)
    x = layers.Dropout(0.4)(x)

    # Block 3
    x = layers.Conv2D(256, (3, 3), padding='same')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.5)(x)

    # Classification head
    x = layers.Dense(128, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.3)(x)
    outputs = layers.Dense(1, activation='sigmoid')(x)

    model = models.Model(inputs=inputs, outputs=outputs)

    model.compile(
        optimizer=Adam(learning_rate=0.0005),
        loss='binary_crossentropy',
        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]
    )

    return model

# Create and train Model 3
model3 = create_attention_cnn()
print("Model 3 Summary:")
model3.summary()

print("\nTraining Model 3...")

callbacks3 = [
    EarlyStopping(monitor='val_auc', patience=7, mode='max',
                  restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4,
                     min_lr=1e-7, verbose=1),
    ModelCheckpoint('model3_best.h5', monitor='val_auc',
                   mode='max', save_best_only=True, verbose=1)
]

history3 = model3.fit(
    train_gen,
    validation_data=val_gen,
    epochs=20,
    callbacks=callbacks3,
    verbose=1
)

# ============================================
# EVALUATE MODEL 3
# ============================================
print("\nEvaluating Model 3...")

y_pred3 = []
for i in range(len(val_gen_no_shuffle)):
    X_batch, _ = val_gen_no_shuffle[i]
    preds = model3.predict(X_batch, verbose=0)
    y_pred3.extend(preds.flatten())

y_pred3 = np.array(y_pred3)
auc3 = roc_auc_score(y_true, y_pred3)
y_pred3_binary = (y_pred3 > 0.5).astype(int)
cm3 = confusion_matrix(y_true, y_pred3_binary)

print(f"Model 3 - Validation AUC: {auc3:.4f}")
print(f"Confusion Matrix:\n{cm3}")

# Save Model 3 results
model3_results = {
    'name': 'Custom CNN with Attention',
    'auc': auc3,
    'history': history3,
    'model': model3,
    'predictions': y_pred3
}

"""After training our 3 models we then take a look at the model comparison through plot visualizations."""

# ============================================
# COMPREHENSIVE MODEL COMPARISON
# ============================================
print("\n" + "="*60)
print("MODEL COMPARISON SUMMARY")
print("="*60)

# Collect results
models_results = [model1_results, model2_results, model3_results]

# Create comparison table
comparison_data = []
for result in models_results:
    comparison_data.append({
        'Model': result['name'],
        'Validation AUC': f"{result['auc']:.4f}",
        'Parameters': f"{result['model'].count_params():,}",
        'Inference Time (ms)': 'N/A'  # Can add timing if needed
    })

comparison_df = pd.DataFrame(comparison_data)
print("\nModel Performance Comparison:")
print(comparison_df.to_string(index=False))

# ============================================
# VISUALIZATION: Training Curves
# ============================================
fig, axes = plt.subplots(2, 3, figsize=(18, 10))

# Model 1 curves
axes[0, 0].plot(history1.history['auc'], label='Train AUC')
axes[0, 0].plot(history1.history['val_auc'], label='Val AUC')
axes[0, 0].set_title('Model 1: Baseline CNN - AUC')
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('AUC')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

axes[1, 0].plot(history1.history['loss'], label='Train Loss')
axes[1, 0].plot(history1.history['val_loss'], label='Val Loss')
axes[1, 0].set_title('Model 1: Baseline CNN - Loss')
axes[1, 0].set_xlabel('Epoch')
axes[1, 0].set_ylabel('Loss')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# Model 2 curves
if isinstance(model2_results['history'], tuple):
    hist1, hist2 = model2_results['history']
    epochs1 = len(hist1.history['auc'])
    epochs2 = epochs1 + len(hist2.history['auc'])

    # Combine histories
    combined_auc = hist1.history['auc'] + hist2.history['auc']
    combined_val_auc = hist1.history['val_auc'] + hist2.history['val_auc']
    combined_loss = hist1.history['loss'] + hist2.history['loss']
    combined_val_loss = hist1.history['val_loss'] + hist2.history['val_loss']

    axes[0, 1].plot(combined_auc, label='Train AUC')
    axes[0, 1].plot(combined_val_auc, label='Val AUC')
    axes[0, 1].axvline(x=epochs1, color='r', linestyle='--', alpha=0.5, label='Fine-tuning start')
else:
    hist = model2_results['history']
    axes[0, 1].plot(hist.history['auc'], label='Train AUC')
    axes[0, 1].plot(hist.history['val_auc'], label='Val AUC')

axes[0, 1].set_title('Model 2: EfficientNet - AUC')
axes[0, 1].set_xlabel('Epoch')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

if isinstance(model2_results['history'], tuple):
    axes[1, 1].plot(combined_loss, label='Train Loss')
    axes[1, 1].plot(combined_val_loss, label='Val Loss')
    axes[1, 1].axvline(x=epochs1, color='r', linestyle='--', alpha=0.5, label='Fine-tuning start')
else:
    axes[1, 1].plot(hist.history['loss'], label='Train Loss')
    axes[1, 1].plot(hist.history['val_loss'], label='Val Loss')

axes[1, 1].set_title('Model 2: EfficientNet - Loss')
axes[1, 1].set_xlabel('Epoch')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

# Model 3 curves
axes[0, 2].plot(history3.history['auc'], label='Train AUC')
axes[0, 2].plot(history3.history['val_auc'], label='Val AUC')
axes[0, 2].set_title('Model 3: Attention CNN - AUC')
axes[0, 2].set_xlabel('Epoch')
axes[0, 2].legend()
axes[0, 2].grid(True, alpha=0.3)

axes[1, 2].plot(history3.history['loss'], label='Train Loss')
axes[1, 2].plot(history3.history['val_loss'], label='Val Loss')
axes[1, 2].set_title('Model 3: Attention CNN - Loss')
axes[1, 2].set_xlabel('Epoch')
axes[1, 2].legend()
axes[1, 2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# ============================================
# VISUALIZATION: ROC Curves Comparison
# ============================================
from sklearn.metrics import roc_curve

fig, ax = plt.subplots(figsize=(10, 8))

# Plot ROC curves for all models
for result in models_results:
    fpr, tpr, _ = roc_curve(y_true, result['predictions'])
    ax.plot(fpr, tpr, label=f"{result['name']} (AUC = {result['auc']:.3f})", linewidth=2)

# Plot random classifier
ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier (AUC = 0.5)')

ax.set_xlabel('False Positive Rate', fontsize=12)
ax.set_ylabel('True Positive Rate', fontsize=12)
ax.set_title('ROC Curves Comparison', fontsize=14, fontweight='bold')
ax.legend(loc='lower right', fontsize=11)
ax.grid(True, alpha=0.3)
ax.set_xlim([0.0, 1.0])
ax.set_ylim([0.0, 1.05])

plt.show()

# ============================================
# VISUALIZATION: Prediction Distributions
# ============================================
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for idx, result in enumerate(models_results):
    ax = axes[idx]

    # Separate predictions by true class
    preds_positive = result['predictions'][y_true == 1]
    preds_negative = result['predictions'][y_true == 0]

    ax.hist(preds_negative, bins=30, alpha=0.7, label='Negative (True Class 0)',
            color='blue', density=True)
    ax.hist(preds_positive, bins=30, alpha=0.7, label='Positive (True Class 1)',
            color='red', density=True)

    ax.set_xlabel('Predicted Probability', fontsize=10)
    ax.set_ylabel('Density', fontsize=10)
    ax.set_title(f"{result['name']}\nAUC: {result['auc']:.4f}", fontsize=11)
    ax.legend(fontsize=9)
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# ============================================
# ARCHITECTURE ANALYSIS & RECOMMENDATIONS
# ============================================
print("\n" + "="*60)
print("ARCHITECTURE ANALYSIS & RECOMMENDATIONS")
print("="*60)

print("\n1. MODEL 1: Baseline CNN")
print("-" * 40)
print("Strengths:")
print("  • Fast training and inference")
print("  • Low memory footprint")
print("  • Easy to interpret and debug")
print("  • Good baseline for comparison")
print("\nWeaknesses:")
print("  • Limited capacity for complex patterns")
print("  • May underfit on subtle tissue differences")
print("  • Requires careful hyperparameter tuning")
print("\nBest Use Case: Initial experimentation, quick prototyping")

print("\n2. MODEL 2: EfficientNet Transfer Learning")
print("-" * 40)
print("Strengths:")
print("  • State-of-the-art performance")
print("  • Pretrained on diverse image dataset")
print("  • Efficient architecture (good FLOPS/accuracy)")
print("  • Excellent feature extraction capability")
print("\nWeaknesses:")
print("  • Larger model size")
print("  • Requires careful fine-tuning strategy")
print("  • May overfit on small datasets")
print("\nBest Use Case: Production deployment, maximum accuracy")

print("\n3. MODEL 3: Custom CNN with Attention")
print("-" * 40)
print("Strengths:")
print("  • Attention mechanism focuses on important regions")
print("  • Residual connections improve gradient flow")
print("  • Customizable for specific problem")
print("  • Good balance of performance and interpretability")
print("\nWeaknesses:")
print("  • Requires more tuning")
print("  • Computational overhead from attention blocks")
print("  • More complex to implement")
print("\nBest Use Case: Research, when interpretability is important")

print("\n" + "="*60)
print("FINAL RECOMMENDATION")
print("="*60)
print(f"\nBased on validation AUC scores:")
print(f"  • Model 1 (Baseline): {model1_results['auc']:.4f}")
print(f"  • Model 2 (EfficientNet): {model2_results['auc']:.4f}")
print(f"  • Model 3 (Attention CNN): {model3_results['auc']:.4f}")

best_model_idx = np.argmax([m['auc'] for m in models_results])
best_model = models_results[best_model_idx]

print(f"\n✅ RECOMMENDED MODEL: {best_model['name']}")
print(f"   with AUC = {best_model['auc']:.4f}")

if best_model['name'] == 'EfficientNet Transfer':
    print("\nNext steps for improvement:")
    print("1. Train on full dataset (not just 10% subset)")
    print("2. Use more aggressive data augmentation")
    print("3. Implement ensemble of multiple EfficientNet variants")
    print("4. Add test-time augmentation")
elif best_model['name'] == 'Custom CNN with Attention':
    print("\nNext steps for improvement:")
    print("1. Visualize attention maps to verify model focus")
    print("2. Add spatial attention alongside channel attention")
    print("3. Experiment with different attention mechanisms")
else:
    print("\nNext steps for improvement:")
    print("1. Increase model capacity (more layers/filters)")
    print("2. Add more sophisticated augmentation")
    print("3. Implement learning rate scheduling")

"""From these models we can see that based on AUC scores our custom cnn with attention outperforms the other two models by a large margin"""

# ============================================
# GENERATE SUBMISSION WITH BEST MODEL
# ============================================
print("\n" + "="*60)
print("GENERATING SUBMISSION FILE")
print("="*60)

def generate_submission(model, test_dir, batch_size=64):
    """Generate predictions for test set"""
    # Get test file names
    test_files = [f for f in os.listdir(test_dir) if f.endswith('.tif')]
    test_ids = [f.replace('.tif', '') for f in test_files]

    print(f"Found {len(test_ids)} test images")

    # Predict in batches to avoid memory issues
    predictions = []

    for i in range(0, len(test_files), batch_size):
        batch_files = test_files[i:i+batch_size]
        batch_images = []

        for f in batch_files:
            img_path = os.path.join(test_dir, f)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (96, 96))
            img = img / 255.0
            batch_images.append(img)

        batch_images = np.array(batch_images)
        batch_preds = model.predict(batch_images, verbose=0)
        predictions.extend(batch_preds.flatten())

        if i % 1000 == 0:
            print(f"Processed {i}/{len(test_files)} images...")

    # Create submission dataframe
    submission_df = pd.DataFrame({
        'id': test_ids,
        'label': predictions
    })

    return submission_df

# Use best model for submission
print(f"\nUsing {best_model['name']} for final predictions...")
submission_df = generate_submission(best_model['model'], test_dir)

# Save submission
submission_file = 'submission.csv'
submission_df.to_csv(submission_file, index=False)
print(f"\n✅ Submission saved to: {submission_file}")
print(f"\nSubmission preview:")
print(submission_df.head())

# ============================================
# HYPERPARAMETER TUNING SUMMARY
# ============================================
print("\n" + "="*60)
print("HYPERPARAMETER TUNING INSIGHTS")
print("="*60)

print("\nKey Hyperparameters & Their Impact:")
print("\n1. Learning Rate:")
print("   • Baseline CNN: 0.001 worked well")
print("   • EfficientNet: 0.0001 for feature extraction, 1e-5 for fine-tuning")
print("   • Too high → unstable training, too low → slow convergence")

print("\n2. Batch Size:")
print("   • 64 provided good balance of speed and gradient stability")
print("   • Smaller batches → more updates, better generalization")
print("   • Larger batches → faster training, more memory needed")

print("\n3. Dropout Rate:")
print("   • Increased from 0.2 to 0.5 in deeper layers")
print("   • Helps prevent overfitting")
print("   • Higher dropout in fully connected layers")

print("\n4. Data Augmentation:")
print("   • Flips (horizontal/vertical) crucial for invariance")
print("   • Rotation (±20°) helps with orientation variations")
print("   • Brightness/contrast adjustments for staining variations")

print("\n5. Callback Strategy:")
print("   • EarlyStopping on val_auc (patience=5-7)")
print("   • ReduceLROnPlateau for learning rate adjustment")
print("   • ModelCheckpoint to save best weights")

# ============================================
# GENERATE SUBMISSION WITH BEST MODEL
# ============================================
print("\n" + "="*60)
print("GENERATING SUBMISSION FILE")
print("="*60)

def generate_submission(model, test_dir, batch_size=64):
    """Generate predictions for test set"""
    # Get test file names
    test_files = [f for f in os.listdir(test_dir) if f.endswith('.tif')]
    test_ids = [f.replace('.tif', '') for f in test_files]

    print(f"Found {len(test_ids)} test images")

    # Predict in batches to avoid memory issues
    predictions = []

    for i in range(0, len(test_files), batch_size):
        batch_files = test_files[i:i+batch_size]
        batch_images = []

        for f in batch_files:
            img_path = os.path.join(test_dir, f)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (96, 96))
            img = img / 255.0
            batch_images.append(img)

        batch_images = np.array(batch_images)
        batch_preds = model.predict(batch_images, verbose=0)
        predictions.extend(batch_preds.flatten())

        if i % 1000 == 0:
            print(f"Processed {i}/{len(test_files)} images...")

    # Create submission dataframe
    submission_df = pd.DataFrame({
        'id': test_ids,
        'label': predictions
    })

    return submission_df

# Use best model for submission
print(f"\nUsing {best_model['name']} for final predictions...")
submission_df = generate_submission(best_model['model'], test_dir)

# Save submission
submission_file = 'submission.csv'
submission_df.to_csv(submission_file, index=False)
print(f"\n✅ Submission saved to: {submission_file}")
print(f"\nSubmission preview:")
print(submission_df.head())

# ============================================
# HYPERPARAMETER TUNING SUMMARY
# ============================================
print("\n" + "="*60)
print("HYPERPARAMETER TUNING INSIGHTS")
print("="*60)

print("\nKey Hyperparameters & Their Impact:")
print("\n1. Learning Rate:")
print("   • Baseline CNN: 0.001 worked well")
print("   • EfficientNet: 0.0001 for feature extraction, 1e-5 for fine-tuning")
print("   • Too high → unstable training, too low → slow convergence")

print("\n2. Batch Size:")
print("   • 64 provided good balance of speed and gradient stability")
print("   • Smaller batches → more updates, better generalization")
print("   • Larger batches → faster training, more memory needed")

print("\n3. Dropout Rate:")
print("   • Increased from 0.2 to 0.5 in deeper layers")
print("   • Helps prevent overfitting")
print("   • Higher dropout in fully connected layers")

print("\n4. Data Augmentation:")
print("   • Flips (horizontal/vertical) crucial for invariance")
print("   • Rotation (±20°) helps with orientation variations")
print("   • Brightness/contrast adjustments for staining variations")

print("\n5. Callback Strategy:")
print("   • EarlyStopping on val_auc (patience=5-7)")
print("   • ReduceLROnPlateau for learning rate adjustment")
print("   • ModelCheckpoint to save best weights")



